{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13983097,"sourceType":"datasetVersion","datasetId":8912935}],"dockerImageVersionId":31192,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"### load libraries ###\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport re # data preprocessing, removing punctuation\n\nimport matplotlib.pyplot as plt # EDA, visualization\nimport seaborn as sns # EDA, visualization\nfrom wordcloud import WordCloud # EDA, word cloud visualization\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer # data preprocessing, matrix vectorization\nfrom sklearn.decomposition import NMF # modeling, unsupervised classification\nfrom sklearn.naive_bayes import MultinomialNB # modeling, classified model\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix # model evaluation","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-09T18:10:45.673739Z","iopub.execute_input":"2025-12-09T18:10:45.674057Z","iopub.status.idle":"2025-12-09T18:10:45.680586Z","shell.execute_reply.started":"2025-12-09T18:10:45.674032Z","shell.execute_reply":"2025-12-09T18:10:45.679069Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"### import datasets ###\n\ntrain_file = '/kaggle/input/bbc-news-classification/BBC News Train.csv'\ntest_file = '/kaggle/input/bbc-news-classification/BBC News Test.csv'\n\ndf_train = pd.read_csv(train_file)\ndf_test = pd.read_csv(test_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T18:10:47.126356Z","iopub.execute_input":"2025-12-09T18:10:47.126844Z","iopub.status.idle":"2025-12-09T18:10:47.220071Z","shell.execute_reply.started":"2025-12-09T18:10:47.126818Z","shell.execute_reply":"2025-12-09T18:10:47.219076Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# check data types\ndf_train.info()\ndf_test.info()\n\n# show data frames\nprint(df_train.head(10))\nprint(df_test.head(10))\n\n# understand category distribution\nprint(df_train['Category'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T18:10:48.557857Z","iopub.execute_input":"2025-12-09T18:10:48.558169Z","iopub.status.idle":"2025-12-09T18:10:48.577286Z","shell.execute_reply.started":"2025-12-09T18:10:48.558147Z","shell.execute_reply":"2025-12-09T18:10:48.576362Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"-\" * 50)\nprint(\"STEP 1: Problem & Data Description\")\nprint(\"-\" * 50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T18:10:52.513767Z","iopub.execute_input":"2025-12-09T18:10:52.514109Z","iopub.status.idle":"2025-12-09T18:10:52.518827Z","shell.execute_reply.started":"2025-12-09T18:10:52.514084Z","shell.execute_reply":"2025-12-09T18:10:52.518074Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Problem**: The original Kaggle competition task for this dataset was to employ both supervised and unsupervised classification methods to predict the category of an article based on its text. For my final assignments, I will:\n* **Unsupervised Classification**: Try to improve the performance of my unsupervised classification model by (1) optimizing my stopwords list and (2) tune my max_features hyperparameter. I will also compare my NMF model to an LDA model.\n\n**Data Description**: Include are a testing dataset and a training dataset. The training dataset includes 1490 samples and the testing dataset includes 735 samples. The features included in these datasets are:\n* **ArticleId**: int64, unique identifier for unique articles\n* **Text**: string, article source text\n* **Category**: object; classification of article; one of five: sport, business, politics, entertainment, tech (only in the training dataset, not the testing dataset)","metadata":{}},{"cell_type":"code","source":"print(\"-\" * 50)\nprint(\"STEP 2a: EDA - Cleaning and Pre-processing\")\nprint(\"-\" * 50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T18:10:56.594010Z","iopub.execute_input":"2025-12-09T18:10:56.594321Z","iopub.status.idle":"2025-12-09T18:10:56.599016Z","shell.execute_reply.started":"2025-12-09T18:10:56.594298Z","shell.execute_reply":"2025-12-09T18:10:56.598052Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"### Data Cleaning and Preprocessing: Lowercasing & Punctuation Removal ###\n# For text vectorization, preprocessing should include setting all words in lowercase; removing punctuation; removing articles and prepositions (\"stop words\"); tokenization; and stemming.\n\n# set words in lowercase\ndf_train['Text'] = df_train['Text'].str.lower()\ndf_test['Text'] = df_test['Text'].str.lower()\n\n# remove punctation\ndef remove_punctuation(text):\n    text = re.sub(r'a-z\\s0-9\\$', '', text) # retain a-z, 0-9, white spaces, and '$'\n    return text\n\ndf_train['Text'] = df_train['Text'].apply(remove_punctuation)\ndf_test['Text'] = df_test['Text'].apply(remove_punctuation)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T18:11:34.191095Z","iopub.execute_input":"2025-12-09T18:11:34.191399Z","iopub.status.idle":"2025-12-09T18:11:34.227351Z","shell.execute_reply.started":"2025-12-09T18:11:34.191377Z","shell.execute_reply":"2025-12-09T18:11:34.226595Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"### Data Cleaning and Preprocessing: Stop Word Removal ###\n# create function to remove stop words\n# network issues when trying to download nltk stopwords, creating list\nSTOPWORDS = set([\n    'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', \n    'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', \n    'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', \n    'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', \n    'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \n    'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', \n    'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', \n    'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', \n    'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', \n    'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', \n    'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', \n    'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 'd', \n    'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', 'couldn', 'didn', 'doesn', 'hadn', \n    'hasn', 'haven', 'isn', 'ma', 'mightn', 'mustn', 'needn', 'shan', 'shouldn', 'wasn', \n    'weren', 'won', 'wouldn', 'sir', 'mr', 'said'\n])\n\ndef remove_stopwords(text):\n    words = text.split() # split text into individual words\n    filtered_words = [word for word in words if word not in STOPWORDS] # filter out stop words\n    return ' '.join(filtered_words)\n\n# remove stop words\ndf_train['Text'] = df_train['Text'].apply(remove_stopwords)\ndf_test['Text'] = df_test['Text'].apply(remove_stopwords)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T18:11:52.764638Z","iopub.execute_input":"2025-12-09T18:11:52.764975Z","iopub.status.idle":"2025-12-09T18:11:52.913371Z","shell.execute_reply.started":"2025-12-09T18:11:52.764953Z","shell.execute_reply":"2025-12-09T18:11:52.912565Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"### Matrix Vectorization ###\n\n# initialize TF-IDF vectorizer\nvectorizer = TfidfVectorizer(max_features = 5000)\n\n# fit and transform the training data\nX_train = vectorizer.fit_transform(df_train['Text'])\n\n# transform test data\nX_test = vectorizer.transform(df_test['Text'])\n\n# print checks\nprint(X_train.shape)\nprint(X_test.shape)\nprint(vectorizer.max_features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T18:11:54.073293Z","iopub.execute_input":"2025-12-09T18:11:54.073737Z","iopub.status.idle":"2025-12-09T18:11:54.539478Z","shell.execute_reply.started":"2025-12-09T18:11:54.073704Z","shell.execute_reply":"2025-12-09T18:11:54.538660Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"-\" * 50)\nprint(\"STEP 2b: EDA - Visualization\")\nprint(\"-\" * 50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T18:19:51.798937Z","iopub.execute_input":"2025-12-09T18:19:51.799798Z","iopub.status.idle":"2025-12-09T18:19:51.804019Z","shell.execute_reply.started":"2025-12-09T18:19:51.799772Z","shell.execute_reply":"2025-12-09T18:19:51.803021Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"### Exploratory Data Analysis ###\n# EDA is used to understand key data characteristics: balance, sparsity, and feature correlation\n\n# Check for balance between categories\nplt.figure(figsize = (10, 6))\nsns.countplot(y = 'Category',\n             data = df_train,\n             order = df_train['Category'].value_counts().index,\n             palette = 'viridis')\nplt.title(\"Article Count per Category\")\nplt.xlabel(\"Number of Articles\")\nplt.ylabel(\"Category\")\nplt.show()\n\n# Show most common word in each category (n = 10)\ndef get_top_n_words(df, category, n = 10):\n    category_text = df[df['Category'] == category]['Text'] # filter for specific category\n\n    vectorize = CountVectorizer(max_features = 5000)\n    X = vectorizer.fit_transform(category_text)\n\n    word_counts = np.sum(X.toarray(), axis = 0)\n    words_df = pd.DataFrame(\n        {'word': vectorizer.get_feature_names_out(), 'count': word_counts}\n    ).sort_values(by = 'count', ascending = False).reset_index(drop = True)\n\n    return words_df.head(n)\n\ncategories = df_train['Category'].unique()\n\nfor category in categories:\n    top_words = get_top_n_words(df_train, category, n = 10)\n    print(f\"\\nCategory: {category.upper()}\")\n    print(top_words)\n\n# sparsity check\nsparsity = 1.0 - (X_train.nnz / (X_train.shape[0] * X_train.shape[1]))\nprint(f\"\\nSparsity of the TF-IDF Matrix: {sparsity:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T17:36:35.202123Z","iopub.execute_input":"2025-12-09T17:36:35.202415Z","iopub.status.idle":"2025-12-09T17:36:35.768587Z","shell.execute_reply.started":"2025-12-09T17:36:35.202395Z","shell.execute_reply":"2025-12-09T17:36:35.767619Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# word clouds (for funsies!)\n\n# business\nbusiness_text = ' '.join(df_train[df_train['Category'] == 'business']['Text'])\n\nwordcloud = WordCloud(width=800, height=400, background_color='white', colormap='Greens').generate(business_text)\n\nplt.figure(figsize=(10, 5))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.title(\"Word Cloud for 'Business' Category\")\nplt.show()\n\n# sport\nsport_text = ' '.join(df_train[df_train['Category'] == 'sport']['Text'])\n\nwordcloud = WordCloud(width=800, height=400, background_color='white', colormap='Blues').generate(sport_text)\n\nplt.figure(figsize=(10, 5))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.title(\"Word Cloud for 'Sport' Category\")\nplt.show()\n\n# politics\npolitics_text = ' '.join(df_train[df_train['Category'] == 'politics']['Text'])\n\nwordcloud = WordCloud(width=800, height=400, background_color='white', colormap='Reds').generate(politics_text)\n\nplt.figure(figsize=(10, 5))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.title(\"Word Cloud for 'Politics' Category\")\nplt.show()\n\n# entertainment\nentertainment_text = ' '.join(df_train[df_train['Category'] == 'entertainment']['Text'])\n\nwordcloud = WordCloud(width=800, height=400, background_color='white', colormap='Purples').generate(entertainment_text)\n\nplt.figure(figsize=(10, 5))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.title(\"Word Cloud for 'Entertainment' Category\")\nplt.show()\n\n# tech\ntech_text = ' '.join(df_train[df_train['Category'] == 'tech']['Text'])\n\nwordcloud = WordCloud(width=800, height=400, background_color='white', colormap='magma').generate(tech_text)\n\nplt.figure(figsize=(10, 5))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.title(\"Word Cloud for 'Tech' Category\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T17:36:38.833560Z","iopub.execute_input":"2025-12-09T17:36:38.834591Z","iopub.status.idle":"2025-12-09T17:36:45.913328Z","shell.execute_reply.started":"2025-12-09T17:36:38.834554Z","shell.execute_reply":"2025-12-09T17:36:45.912444Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"-\" * 50)\nprint(\"STEP C: Model Building and Training\")\nprint(\"-\" * 50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T17:36:51.932075Z","iopub.execute_input":"2025-12-09T17:36:51.932391Z","iopub.status.idle":"2025-12-09T17:36:51.937768Z","shell.execute_reply.started":"2025-12-09T17:36:51.932368Z","shell.execute_reply":"2025-12-09T17:36:51.936603Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"### Unsupervised Model Building and Training ###\n\n## Non-Negative Matrix Factorization ##\n\n# unsupervised classification using NMF\nNUM_TOPICS = 5 # no. of categories\nnmf_model = NMF(n_components = NUM_TOPICS,\n               random_state = 42,\n               max_iter = 500,\n               tol = 0.0001)\n\n# fit model to matrix\nW_train = nmf_model.fit_transform(X_train)\nH = nmf_model.components_\n\n## NMF Outcomes ##\n\nnmf_predictions = np.argmax(W_train, axis=1) # highest-weighted topic for each document\ndf_train['NMF_Topic_ID'] = nmf_predictions # add predictions to the training DataFrame for comparison\n\n# Create a crosstab to show the relationship between True Labels and NMF Topics\ntopic_category_mapping = pd.crosstab(df_train['NMF_Topic_ID'], df_train['Category'])\n\n# Plot the crosstab as a heatmap for better visualization\nplt.figure(figsize=(10, 6))\nsns.heatmap(topic_category_mapping, annot=True, fmt='d', cmap='Blues', linewidths=.5, linecolor='black')\nplt.title('NMF Topic ID vs. True Category Count')\nplt.ylabel('NMF Topic ID')\nplt.xlabel('True Category')\nplt.show()\n\n# adjust dictionary\nfinal_map = {\n    0: 'sport',\n    1: 'politics',\n    2: 'tech',\n    3: 'entertainment',\n    4: 'business'\n}\n\n# map predicted Topic IDs to the new labels\ndf_train['NMF_Predicted_Category'] = df_train['NMF_Topic_ID'].map(final_map)\n\n# calculate Accuracy\naccuracy = accuracy_score(df_train['Category'], df_train['NMF_Predicted_Category'])\nprint(accuracy)\n\n# display a full Classification Report for Precision, Recall, and F1-score\nprint(\"\\nNMF Classification Report (Training Data):\\n\")\nprint(classification_report(df_train['Category'], df_train['NMF_Predicted_Category']))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T17:36:52.347340Z","iopub.execute_input":"2025-12-09T17:36:52.348171Z","iopub.status.idle":"2025-12-09T17:36:52.855056Z","shell.execute_reply.started":"2025-12-09T17:36:52.348140Z","shell.execute_reply":"2025-12-09T17:36:52.854300Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## NMF Optimization: lower max_features ##\n# initialize TF-IDF vectorizer\nvectorizer_lower = TfidfVectorizer(max_features = 10000)\n\n# fit and transform the training data\nX_train_lower = vectorizer_lower.fit_transform(df_train['Text'])\n\n# transform test data\nX_test_lower = vectorizer_lower.transform(df_test['Text'])\n\n# print checks\nprint(X_train_lower.shape)\nprint(X_test_lower.shape)\nprint(vectorizer_lower.max_features)\n\n# unsupervised classification using NMF\nNUM_TOPICS_LOW = 5 # no. of categories\nnmf_model_lower = NMF(n_components = NUM_TOPICS_LOW,\n               random_state = 42,\n               max_iter = 500,\n               tol = 0.0001)\n\n# fit model to matrix\nW_train_lower = nmf_model_lower.fit_transform(X_train_lower)\nH_lower = nmf_model_lower.components_\n\n## NMF Outcomes ##\n\nnmf_predictions_lower = np.argmax(W_train_lower, axis=1) # highest-weighted topic for each document\ndf_train['NMF_Topic_ID'] = nmf_predictions_lower # add predictions to the training DataFrame for comparison\n\n# Create a crosstab to show the relationship between True Labels and NMF Topics\ntopic_category_mapping_lower = pd.crosstab(df_train['NMF_Topic_ID'], df_train['Category'])\n\n# Plot the crosstab as a heatmap for better visualization\nplt.figure(figsize=(10, 6))\nsns.heatmap(topic_category_mapping_lower, annot=True, fmt='d', cmap='Blues', linewidths=.5, linecolor='black')\nplt.title('NMF Topic ID vs. True Category Count')\nplt.ylabel('NMF Topic ID')\nplt.xlabel('True Category')\nplt.show()\n\n# adjust dictionary\nfinal_map = {\n    0: 'sport',\n    1: 'politics',\n    2: 'tech',\n    3: 'entertainment',\n    4: 'business'\n}\n\n# map predicted Topic IDs to the new labels\ndf_train['NMF_Predicted_Category'] = df_train['NMF_Topic_ID'].map(final_map)\n\n# calculate Accuracy\naccuracy = accuracy_score(df_train['Category'], df_train['NMF_Predicted_Category'])\nprint(accuracy)\n\n# display a full Classification Report for Precision, Recall, and F1-score\nprint(\"\\nNMF Classification Report (Training Data):\\n\")\nprint(classification_report(df_train['Category'], df_train['NMF_Predicted_Category']))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T17:36:56.772163Z","iopub.execute_input":"2025-12-09T17:36:56.772588Z","iopub.status.idle":"2025-12-09T17:36:57.780761Z","shell.execute_reply.started":"2025-12-09T17:36:56.772560Z","shell.execute_reply":"2025-12-09T17:36:57.779895Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## NMF Optimization ##\n\n# refine stopwords\n\nCUSTOM_STOPWORDS = set([\n    'year', 'new', 'time', 'make', 'market', 'government', 'country', \n    'england', 'firm', 'world', 'us', 'people', 'best', 'number', 'uk', 'business', 'said'\n])\n\nOPTIMIZED_STOPWORDS = STOPWORDS.union(CUSTOM_STOPWORDS)\n\ndf_train_nmf_opt = df_train.copy()\ndf_test_nmf_opt = df_test.copy()\n\ndf_train_nmf_opt = pd.read_csv(train_file)\ndf_train_nmf_opt['Text'] = df_train_nmf_opt['Text'].str.lower()\ndf_train_nmf_opt['Text'] = df_train_nmf_opt['Text'].apply(remove_punctuation)\n\n# Apply the new, optimized stopword list\ndef remove_optimized_stopwords(text):\n    words = text.split()\n    filtered_words = [word for word in words if word not in OPTIMIZED_STOPWORDS]\n    return ' '.join(filtered_words)\n\ndf_train_nmf_opt['Text'] = df_train_nmf_opt['Text'].apply(remove_optimized_stopwords)\n\n\n## Re-vectorize and tune NMF ##\n\n# re-initialize TF-IDF vectorizer with the same max_features\nnmf_opt_vectorizer = TfidfVectorizer(max_features=5000)\n\n# fit and transform the new, cleaned training data\nX_train_nmf_opt = nmf_opt_vectorizer.fit_transform(df_train_nmf_opt['Text'])\n\nNUM_TOPICS_OPT = 5 \n\nnmf_opt_model = NMF(n_components=NUM_TOPICS_OPT,\n               random_state=42,\n               max_iter=500,\n               tol=0.0001)\n\n# fit model to new matrix\nW_train_opt = nmf_opt_model.fit_transform(X_train_nmf_opt)\nH_opt = nmf_opt_model.components_\n\nprint(f\"\\n--- NMF Optimization Training Complete (Topics: {NUM_TOPICS_OPT}) ---\")\n\n# top N words for each category\n\nfeature_names = nmf_opt_vectorizer.get_feature_names_out()\n\n# Function to display the top words for each topic\ndef display_topics(model, feature_names, no_top_words):\n    for topic_idx, topic in enumerate(model.components_):\n        top_features_ind = topic.argsort()[:-no_top_words - 1:-1]\n        top_features = [feature_names[i] for i in top_features_ind]\n        print(f\"Topic {topic_idx}: {' '.join(top_features)}\")\n\nprint(\"\\nTop 10 words for each NMF Topic:\")\ndisplay_topics(nmf_opt_model, feature_names, 10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T17:37:02.578103Z","iopub.execute_input":"2025-12-09T17:37:02.578420Z","iopub.status.idle":"2025-12-09T17:37:03.278233Z","shell.execute_reply.started":"2025-12-09T17:37:02.578396Z","shell.execute_reply":"2025-12-09T17:37:03.276976Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## NMF Optimization: Evaluation ##\n\n# determine the highest-weighted topic for each document\nnmf_opt_predictions = np.argmax(W_train_opt, axis=1)\ndf_train_nmf_opt['NMF_Topic_ID'] = nmf_opt_predictions\n\n# create a crosstab to show the relationship between True Labels and NEW NMF Topics\ntopic_category_mapping_opt = pd.crosstab(df_train_nmf_opt['NMF_Topic_ID'], df_train_nmf_opt['Category'])\n\nprint(\"\\nNMF Topic ID vs. True Category Count (Optimized Model)\")\nprint(topic_category_mapping_opt)\n\n# mapping based on assumed cleanest fit (CHECK YOUR OUTPUT!)\nfinal_map_opt = {\n    0: 'sport',\n    1: 'politics',\n    2: 'tech',\n    3: 'entertainment',\n    4: 'business'\n}\n\n# map predicted Topic IDs to the new labels\ndf_train_nmf_opt['NMF_Predicted_Category'] = df_train_nmf_opt['NMF_Topic_ID'].map(final_map_opt)\n\n# calculate Accuracy\naccuracy_nmf_opt = accuracy_score(df_train_nmf_opt['Category'], df_train_nmf_opt['NMF_Predicted_Category'])\nprint(f\"\\nOptimized NMF Accuracy: {accuracy_nmf_opt:.4f}\")\n\n# display a full Classification Report\nprint(\"\\nOptimized NMF Classification Report (Training Data):\\n\")\nprint(classification_report(df_train_nmf_opt['Category'], df_train_nmf_opt['NMF_Predicted_Category']))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T17:48:26.532293Z","iopub.execute_input":"2025-12-09T17:48:26.532623Z","iopub.status.idle":"2025-12-09T17:48:26.595624Z","shell.execute_reply.started":"2025-12-09T17:48:26.532601Z","shell.execute_reply":"2025-12-09T17:48:26.594813Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Try a Latent Dirichlet Allocation (LDA) Model ##\n# uses count vectors instead of TF-IDF\nfrom sklearn.decomposition import LatentDirichletAllocation\n\n# convert the set of stopwords to a list as required by CountVectorizer\nstop_words_list = list(OPTIMIZED_STOPWORDS)\n\n# count vectorization initialization\n# use the OPTIMIZED stopword list and the max_features you selected from NMF tuning.\ncount_vectorizer = CountVectorizer(max_features=5000, stop_words=stop_words_list) \nX_train_count = count_vectorizer.fit_transform(df_train_nmf_opt['Text'])\n\n# initiate model\nNUM_TOPICS_LDA = 5\nlda_model = LatentDirichletAllocation(n_components=NUM_TOPICS_LDA, \n                                      max_iter=10, # Standard setting; can be tuned\n                                      learning_method='online', \n                                      random_state=42, \n                                      n_jobs=-1)\n\n# fit and transform\nW_train_lda = lda_model.fit_transform(X_train_count)\n\n# evaluation\nlda_predictions = np.argmax(W_train_lda, axis=1)\n\n# crosstab\ntopic_category_mapping_lda = pd.crosstab(lda_predictions, df_train_nmf_opt['Category'])\nprint(\"\\nLDA Topic ID vs. True Category Count:\")\nprint(topic_category_mapping_lda)\n\n# mapping based on assumed cleanest fit\nlda_final_map = {\n    0: 'entertainment',\n    1: 'politics',\n    2: 'sport',\n    3: 'tech',\n    4: 'business'\n}\n\n# Step 1: Assign LDA predictions to the DataFrame\ndf_train_nmf_opt['LDA_Topic_ID'] = lda_predictions\n\n# Step 2: Map the predicted Topic IDs to the final category labels\n# NOTE: YOU MUST define lda_final_map based on your crosstab output first!\ndf_train_nmf_opt['LDA_Predicted_Category'] = df_train_nmf_opt['LDA_Topic_ID'].map(lda_final_map)\n\n# Step 3: Calculate Accuracy\naccuracy_lda = accuracy_score(df_train_nmf_opt['Category'], df_train_nmf_opt['LDA_Predicted_Category'])\n\n# Step 4: Print Results\nprint(\"\\n\" + \"=\"*50)\nprint(f\"LDA Model Accuracy: {accuracy_lda:.4f}\")\nprint(\"=\"*50)\n\nprint(\"\\nLDA Classification Report (Training Data):\\n\")\nprint(classification_report(df_train_nmf_opt['Category'], df_train_nmf_opt['LDA_Predicted_Category']))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T17:44:01.342946Z","iopub.execute_input":"2025-12-09T17:44:01.343300Z","iopub.status.idle":"2025-12-09T17:44:07.038565Z","shell.execute_reply.started":"2025-12-09T17:44:01.343277Z","shell.execute_reply":"2025-12-09T17:44:07.037574Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1. Get the feature names (words) from the CountVectorizer\nfeature_names_lda = count_vectorizer.get_feature_names_out()\n\n# 2. Function to display the top words for each topic (re-using your NMF function structure)\ndef display_topics_lda(model, feature_names, no_top_words):\n    print(\"\\n--- LDA Topic Interpretation ---\")\n    for topic_idx, topic in enumerate(model.components_):\n        # topic.argsort() finds the indices that would sort the array\n        # [::-1] reverses it to get descending order\n        top_features_ind = topic.argsort()[:-no_top_words - 1:-1]\n        top_features = [feature_names[i] for i in top_features_ind]\n        \n        # Determine the assumed category based on your map for clarity\n        category = lda_final_map.get(topic_idx, 'Unknown')\n        \n        print(f\"Topic {topic_idx} ({category.upper()}): {' '.join(top_features)}\")\n\n# 3. Call the function\ndisplay_topics_lda(lda_model, feature_names_lda, 10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T17:48:32.885721Z","iopub.execute_input":"2025-12-09T17:48:32.886032Z","iopub.status.idle":"2025-12-09T17:48:32.898150Z","shell.execute_reply.started":"2025-12-09T17:48:32.886011Z","shell.execute_reply":"2025-12-09T17:48:32.897262Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"-\" * 50)\nprint(\"STEP D: Results and Discussion\")\nprint(\"-\" * 50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T18:07:34.377658Z","iopub.execute_input":"2025-12-09T18:07:34.378560Z","iopub.status.idle":"2025-12-09T18:07:34.383498Z","shell.execute_reply.started":"2025-12-09T18:07:34.378519Z","shell.execute_reply":"2025-12-09T18:07:34.382672Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Model Accuracy Results**\n* **Baseline NMF** - Accuracy: 0.9235\n* **Optimized NMF** - Accuracy: 0.9255\n* **Latent Dirichlet Allocation (LDA)** - Accuracy: 0.7866\n\n### **Discussion**\nThe non-negative matrix factorization (NMF) model performed significantly better than the latent dirichlet allocation (LDA) model. This is largely due to the different vectorization methods employed by each model.\n\nThe NMF model uses a TF-IDF vectorization method, which puts weight on **unique, defining keywords** that are common in one category but rare in the other categories. In other words, in a TF-IDF vectorization, the most important differentiation words have the heighest weights.\n\nOn the other hand, the LDA model uses a count vector, which puts weight simply on the **most frequent words without** considering whether those words are frequent across multiple categories. In other words, in a count vectorization the highest weighted words are not the most differentiating words.","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}